{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1408143e-5fa4-4c09-beb8-bb3843333407",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afe50cc-66a6-4b3d-b086-9bee6d01a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f4ef7-776e-4e10-9a3d-158a045be037",
   "metadata": {},
   "source": [
    "The idea we pursued to create the graph is the following:\n",
    "export the data to pandas dataframes, work on the dataframes and then exploit the built in function of networkx to convert the dataframe into a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab4ae26-b912-4c77-8e4e-5f9f0f55c194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_q=pd.read_csv('a2q',sep=' ', names=['u','v','t'])  #answers to questions\n",
    "c_a=pd.read_csv('c2a',sep=' ', names=['u','v','t'])  #comments to answers\n",
    "c_q=pd.read_csv('c2q',sep=' ', names=['u','v','t'])  #comments to questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245c0a7c-7be6-4c4f-b6c6-ad39e94f271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17823525, 3) (25405374, 3) (20268151, 3)\n"
     ]
    }
   ],
   "source": [
    "print(a_q.shape,c_a.shape,c_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce931860-3e69-45cc-8212-1f14cc0f9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change time to hours\n",
    "a_q['t'] = a_q['t'].div(3600)\n",
    "c_a['t'] = c_a['t'].div(3600)\n",
    "c_q['t'] = c_q['t'].div(3600)\n",
    "\n",
    "#add type column to dataframes\n",
    "a_q['type'] = 'a_q'\n",
    "c_a['type'] = 'c_a'\n",
    "c_q['type'] = 'c_q'\n",
    "\n",
    "#add weights column initial value of 1\n",
    "a_q['weight'] = 1\n",
    "c_a['weight'] = 1\n",
    "c_q['weight'] = 1\n",
    "\n",
    "#sort by time\n",
    "a_q=a_q.sort_values('t')\n",
    "c_a=c_a.sort_values('t')\n",
    "c_q=c_q.sort_values('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3340f0f4-ba30-497b-88c5-cde6b34b290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_maxmin(data,min,max): #Retrieve maximum and minimum timestamps of a given dataframe\n",
    "    m = data['t'].min()\n",
    "    M = data['t'].max()\n",
    "    if m < min:\n",
    "        min = m \n",
    "    if M > max:\n",
    "        max = M\n",
    "    return min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ed4723-cfda-4007-b002-2021c22b521e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_graph(data1,time_window,self_loops=0):\n",
    "    #remove rows with u=v if we don't want self loops\n",
    "    if self_loops == 0: \n",
    "        data1 = data1[data1['u'] != data1['v']]\n",
    "    \n",
    "    #remove rows not having time 't' in given time interval\n",
    "    data1 = data1[data1['t'].between(time_window[0], time_window[1])]\n",
    "    \n",
    "    #assign weight --> 1 for every edge ,+1 every time u,v (interact)\n",
    "    #also remove multiple links bewtween 2 nodes and leave one that has weight 1+#interactions between the nodes\n",
    "    D = data1[['u','v']]\n",
    "    D = D[D.duplicated(keep=False)]\n",
    "    D = D.groupby(list(D)).apply(lambda x: tuple(x.index)).tolist()\n",
    "    for d in D:\n",
    "        ind = list(d)\n",
    "        val = len(ind)\n",
    "        drop = ind[:-1]\n",
    "        data1.at[ind[-1], 'weight'] = val\n",
    "        data1 = data1.drop(index = drop)\n",
    "    \n",
    "    #convert the dataframe into a multi directed graph with attributes of edges being: last time of interaction, type of interaction and weight of interaction\n",
    "    G = nx.from_pandas_edgelist(data1, 'u', 'v', ['t', 'type', 'weight'], create_using = nx.MultiDiGraph())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e398d54-906b-4a26-ae3b-e921a36d17e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338213.2991666667 404798.1744444444\n"
     ]
    }
   ],
   "source": [
    "#here we get maximum and minimum timestamps of the whole data\n",
    "m = 10**(10)\n",
    "M = 0\n",
    "m, M = time_maxmin(a_q, m, M)\n",
    "m, M = time_maxmin(c_a, m, M)\n",
    "m, M = time_maxmin(c_q, m, M)\n",
    "print(m, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94854c30-6533-4886-b75e-4e75453c315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obviously choose a time window that's inside (m,M)\n",
    "time_window = (m, m+350)\n",
    "#and create the graphs out of the 3 dataframes\n",
    "A = create_graph(a_q, time_window)\n",
    "B = create_graph(c_a, time_window)\n",
    "C = create_graph(c_q, time_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de57b6e-3d3c-4004-8eb7-f5b652aed930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the graphs\n",
    "G = nx.compose_all([A, B, C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34d6d34-0d51-4e12-8f3d-b7e5477d0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_edges(G,time_window):\n",
    "    to_drop=[]\n",
    "    for u,v,att in G.edges(data=True):\n",
    "        if not time_window[0] <= att['t'] <= time_window[1]:\n",
    "            to_drop.append((u, v))\n",
    "    [G.remove_edge(u,v) for (u,v) in to_drop]\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad806806-f0e4-4ad4-b02b-98a255fa0c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3790"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5717182f-1e0f-47bc-b510-17c7b43c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=drop_edges(G,(m+50,m+100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90dcc30c-dcb2-4825-be24-8180ead38374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f983261-b90b-4420-a248-5360fd58742e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38ce4c-8533-447e-a59d-8f2fe1f54598",
   "metadata": {},
   "source": [
    "## function 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62f930-8512-4d59-8434-6759fb3601c5",
   "metadata": {},
   "source": [
    "It takes in input:\n",
    "\n",
    "    One of the 3 graphs\n",
    "\n",
    "The output should return:\n",
    "\n",
    "    Whether the graph is directed or not\n",
    "    Number of users\n",
    "    Number of answers/comments\n",
    "    Average number of links per user\n",
    "    Density degree of the graph\n",
    "    Whether the graph is sparse or dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a992ce6c-477e-42df-82db-286732337f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_1(G):\n",
    "    feats=[] \n",
    "    #m = G.number_of_edges()    = n_interactions\n",
    "    #n = sum(G.nodes)           = n_users\n",
    "    \n",
    "    n_interactions = 0\n",
    "    dir_list = []\n",
    "    users=[]\n",
    "    \n",
    "    for u,v,attr in (G.edges(data=True)):\n",
    "        if (G.has_edge(v,u)) and (n_interactions<=len(A.edges(data=True))/2) :\n",
    "            dir_list.append(abs(attr['weight']-G.get_edge_data(72, 9)[0]['weight']))\n",
    "        \n",
    "        if u not in users: users.append(u) #update the users list\n",
    "        if v not in users: users.append(v)\n",
    "\n",
    "        n_interactions += 1 #count interactions\n",
    "        \n",
    "    if all(val == 0 for val in dir_list): direct=False\n",
    "    else: direct=True\n",
    "    \n",
    "    n_users = len(users) #cpount users\n",
    "     \n",
    "    avg_links = 0 #initialize values for avg links and density\n",
    "    density = 0\n",
    "    g = None\n",
    "    if n_users>0: \n",
    "        avg_links = n_interactions/n_users #just compute a mean\n",
    "        \n",
    "        if direct: # we have the 2 cases for directed and undirected graph\n",
    "            density = 2*n_interactions/(n_users*(n_users-1))\n",
    "        else:\n",
    "            density = n_interactions/(n_users*(n_users-1))\n",
    "                                \n",
    "        if density>0.5: #this is straightforward: we are defining a graph to be sparse if its density value<0.5 and dense otherwise\n",
    "            g='dense'\n",
    "        else:\n",
    "            g='sparse'\n",
    "        \n",
    "    #return list with asked values\n",
    "    feats.extend((direct, n_users, n_interactions, avg_links, density, g))\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdcabc1-80f5-4bb2-8b86-38048f2fde2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, 775, 3790, 4.890322580645162, 0.012636492456447445, 'sparse']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functionality_1(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76661df-0e8a-4ebe-9a00-c6105823bb85",
   "metadata": {},
   "source": [
    "## function 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc89aa-6ba7-44ad-a2ae-570def036bb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "It takes in input:\n",
    "\n",
    "    A user/node\n",
    "    An interval of time\n",
    "    One of the following metrics: Betweeness 1, PageRank, ClosenessCentrality 3, DegreeCentrality\n",
    "\n",
    "The output should return:\n",
    "\n",
    "    The value of the given metric applied over the complete graph for the given interval of time\n",
    "\n",
    "Give an explanaition regarding the features of the user based on all of the metrics (e.g. if the betweeness metric is high, what does this mean in practice, what if the betweeness is low but it has a high PageRank value, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2417bd-91f8-4230-aeb5-4002cd35517a",
   "metadata": {},
   "source": [
    "### PageRank (Random surfer model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182faf12-c06e-4cef-acd8-d008cfa7de59",
   "metadata": {},
   "source": [
    "To compure PageRank we first create the adjacency matrix of the graph, then build the $P^{RW}$ matrix, and after that we assign $\\alpha=0.2$ to create the $P$ matrix using the formula:\n",
    "\n",
    "Given $n=\\#nodes$\n",
    "\n",
    "$P=\\frac{\\alpha}{n}M_1+(1-\\alpha)P^{RW}$ where $M_1$ is a $nxn$ matrix filled with ones.\n",
    "\n",
    "After this just compute for a time $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a78caa-47d3-455e-befe-7b60864919a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_matrix(G,n): #create adjacency matrix of the graph\n",
    "    if n == 0: raise('No nodes found')\n",
    "    else: #we opted for doing it with a  dictionary in which we store a 1 if there is a edge between the 2 nodes\n",
    "        ones = {} \n",
    "        \n",
    "        for u,v in sorted(list(G.edges())):\n",
    "            ones[(u,v)] = 1 \n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9894a92e-db24-4a1f-be56-8a1e94f0db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(G): #return dictionary with nodes as keys and index in matrix as value\n",
    "    conv={}    #maps from nodes to values in matrix, can be used in the other way too\n",
    "    counter=0\n",
    "    for u in sorted(G.nodes):\n",
    "        conv[u]=counter\n",
    "        counter+=1\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dc224c-66c1-466f-9408-b4443f3f0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_tp_P(G,mat,mapper,n):\n",
    "    keys = list(mat.keys())\n",
    "    c = Counter(u for u,v in keys) #count number of occurances of each node, so we know by what value we have to divide to obtain P^{RW}\n",
    "    for source in sorted(list(G)):\n",
    "        for (u,v) in keys:\n",
    "            if source == u and c[source] > 0:\n",
    "                mat[(u,v)] = 1/c[source] #we divide by the value here\n",
    "    keys = list(mat.keys())\n",
    "    M=np.zeros(shape=(n,n)) #build ndarray (aka matrix of P^{RW}) nxn \n",
    "    for (u,v) in keys:\n",
    "        value=mat[(u,v)]\n",
    "        i=mapper[u]\n",
    "        j=mapper[v]\n",
    "        M[i][j]=value\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ee1c5c0-562a-47e7-ae99-7e4108351e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_P(M, alpha, n): #create the P matrix from given alpha and P^{RW}\n",
    "    P = (alpha/n * np.ones((n,n))) + ((1-alpha)*(M))   \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c86bafb1-637b-49f8-9775-aab9f89e0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSurfer(G, u, alpha, n, T=100): #T=time, aka n_iterations\n",
    "    \n",
    "    print('sit back and relax, this is going to take some time')\n",
    "    \n",
    "    #Build P\n",
    "    mat = build_adj_matrix(G,n) \n",
    "    mapp = mapper(G)\n",
    "    mat = no_tp_P(G,mat,mapp,n)\n",
    "    P = build_P(mat, alpha, n)\n",
    "    \n",
    "    #retrieve index of given node in the matrix\n",
    "    ind=mapp[u]\n",
    "    \n",
    "    #randomize the starting point\n",
    "    start = random.randint(0,n)\n",
    "    #retrieve node given its index in amtrix\n",
    "    key_list = list(mapp.keys())\n",
    "    val_list = list(mapp.values())\n",
    "    s = key_list[val_list.index(start)] #s=starting node\n",
    "    \n",
    "    print(('starting from node {}').format(s))\n",
    "    \n",
    "    #initialize vecotr with all zeros except 1 at starting point\n",
    "    q0=np.zeros((n,1))\n",
    "    q0[start]=1\n",
    "    store_value=[]\n",
    "    conv=False\n",
    "    for t in tqdm(range(T)):\n",
    "        q = np.matmul(q0.T, np.linalg.matrix_power(P, t)) #q_t=q0 * P^t\n",
    "        if (t>0) and (np.array_equal(q, store_value[-1])):\n",
    "            print(('converged in {} steps').format(t-1))\n",
    "            q=store_value[-2] #else we are taking a all zeros array\n",
    "            conv=True\n",
    "            break\n",
    "        store_value.append(q)\n",
    "    if conv == False: print(\"didn't converge\")\n",
    "    return q[0][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7994f060-631a-46c6-80c3-8024b29e09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit back and relax, this is going to take some time\n",
      "starting from node 493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:09<00:00, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn't converge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.372226103428674e-08"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomSurfer(G, 13, 0.2, len(G), T=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938aa68-5b94-4398-8d32-3aa947bf5b2e",
   "metadata": {},
   "source": [
    "### Closeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61595363-bf09-4d18-a221-929ec86ce9e9",
   "metadata": {},
   "source": [
    "Computed as\n",
    "\n",
    "$Closeness(v)= \\frac{\\sum_{u,w\\epsilon V \\setminus\\{v\\}} \\frac{g_{u,v}^v}{g_{u,v}}}{{n-1 \\choose 2}}$\n",
    "\n",
    "where:\n",
    "* $g_{u,v}^v = $ # shortest paths between the 2 nodes (u,w) passing through v,\n",
    "* $g_{u,v} = $ # shortest paths between the 2 nodes (u,w),\n",
    "* $n = $ # nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3683136d-4f82-45b2-909e-f3f98c2ab919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(G,source,target):\n",
    "    dist = {}\n",
    "    prev = {}\n",
    "    nodes_list=[]\n",
    "    #Initializatio\n",
    "    for node in nx.nodes(G):\n",
    "        dist.update({node : math.inf}) # A dict with the nodes and the distances (We initialize all the distances as + infinite)\n",
    "        prev.update({node : None}) # A dict with the previous node of each node \n",
    "        nodes_list.append(node) # A list with the nodes that have not been visited\n",
    "    dist[source] = 0 # We initialize the distance of the source node as 0\n",
    "    \n",
    "    while len(nodes_list) != 0: # We will do the next steps until we'll have visited all the nodes are we'll have found the target node\n",
    "       \n",
    "        # the algorithm starts visiting the node with the lower distance\n",
    "        dist_list =[] \n",
    "        for node in nodes_list:\n",
    "            dist_list.append(dist[node])\n",
    "        u = nodes_list[dist_list.index(min(dist_list))]\n",
    "        nodes_list.remove(u) # removing the node from the list of the nodes that have not been visited\n",
    "        \n",
    "        #If the visited node il the target stop the visits\n",
    "        if u == target:\n",
    "            break\n",
    "            \n",
    "        #Otherwise we look at the neighbors\n",
    "        for neighbor in G.neighbors(u):\n",
    "            #computing the new distances for all neighbors\n",
    "            new_dist = dist[u] + G[u][neighbor][0]['weight']\n",
    "            #If the new distance is lower than the previous one we update di distances dict\n",
    "            if dist[neighbor] > new_dist:\n",
    "                dist[neighbor] = new_dist\n",
    "                prev[neighbor] = u\n",
    "                \n",
    "    #If the target has not a previous node it means that there is nott a path (the graph is not connected) so the algorithm\n",
    "    #returns 'not possible'\n",
    "    if prev[target] == None:\n",
    "        return ('Not possible', [-1])\n",
    "    \n",
    "    #creating a list with the path from the source node to the target\n",
    "    path_node = target\n",
    "    path = [path_node]\n",
    "    \n",
    "    while path_node != source:\n",
    "    \n",
    "        path.insert(0,prev[path_node])\n",
    "        path_node = prev[path_node]\n",
    "    \n",
    "    #The algorithm returns the distance of the target and the path\n",
    "    return dist[target], path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05584a09-e1e1-47f4-959c-c264f0e9f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Closeness(G,u,n):\n",
    "    somma=0\n",
    "    for v in tqdm(G.nodes):\n",
    "        dist,path=shortest_path(G,u,v)\n",
    "        if (dist!='Not possible') and (dist!=0):\n",
    "            somma+=int(dist)\n",
    "    #print(somma)\n",
    "    if somma>0: return ((n-1)/somma)\n",
    "    else: raise('Error: sum=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ab2fafc-1d3d-485b-8ebe-a140845084c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 775/775 [00:14<00:00, 54.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5108910891089109"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Closeness(G,13,len(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8cfc1-65d6-432b-9e28-8ce8e9a6eb21",
   "metadata": {},
   "source": [
    "### Betweenness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1cbcc0-9b50-4d84-bfe6-57aa18d85b0a",
   "metadata": {},
   "source": [
    "Computed as\n",
    "\n",
    "$Betweenness(v)= \\frac{n-1}{\\sum_{u\\epsilon V \\setminus\\{v\\}}d(v,u)}$\n",
    "where $d(v,u)=$ shortest path distance between (u,v)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501a4a77-1f17-43b0-bfa5-ada1667bb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Betweenness(G,q,n):\n",
    "    print(\"You chose to use betweenness, we suggest you to go out and take a hangover, you'll be fine before this is over\")\n",
    "    somma_q = 0\n",
    "    somma = 0\n",
    "    for u in tqdm(G.nodes):\n",
    "        for v in (G.nodes):\n",
    "            dist,path = shortest_path(G,u,v)\n",
    "            if (dist!='Not possible') and (dist!=0):\n",
    "                somma+=int(dist)\n",
    "                if q in path:\n",
    "                    somma_q+=int(dist)\n",
    "    \n",
    "    num = 2*somma_q/somma\n",
    "    den = n*n - 3*n + 2\n",
    "    if den>0: return num/den\n",
    "    else: raise('Error: denominator=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4f80f46-08ae-4b82-a130-5ce4914fce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose to use betweenness, we suggest you to go out and take a hangover, you'll be fine before this is over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 775/775 [3:22:07<00:00, 15.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.5679844400311824e-08"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Betweenness(G,13,len(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a681c63-17b2-45bc-949d-b8433d072cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_2(G, u, metric, time_interval, alpha=0.2):  #functionality 2: return the queried metric for the given node\n",
    "    values = functionality_1(G)\n",
    "    n = values[1]\n",
    "    G=drop_edges(G,time_interval)\n",
    "    if metric == 'Betweeness':\n",
    "        return Betweenness(G,u,n)\n",
    "    \n",
    "    elif metric == 'PageRank':\n",
    "        return RandomSurfer(G, u, alpha, n)\n",
    "    \n",
    "    elif metric == 'Closeness':\n",
    "        return Closeness(G,u,n)\n",
    "    \n",
    "    elif metric == 'Degree':\n",
    "        return (G.degree(int(u))/(n-1))\n",
    "    \n",
    "    else:\n",
    "        raise('Metric not allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2a5ec6d-34ea-434a-b9b2-0c00650b72d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit back and relax, this is going to take some time\n",
      "starting from node 1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:08<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn't converge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2664142669969493e-08"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functionality_2(G,13,'PageRank',(m,m+1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ee6f0-1b9f-4075-8aaf-e6a6341d92c5",
   "metadata": {},
   "source": [
    "### Functionality 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22f99afb-6023-4c67-a473-f02dee2e7591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def functionality_3(G,users,source,target):\n",
    "    s_p = shortest_path(G,source,users[0])\n",
    "    dist = s_p[0]\n",
    "    path = s_p[1]\n",
    "    if dist == 'Not possible':\n",
    "        return 'Not possible'\n",
    "    \n",
    "    for i in range(len(users)-1):\n",
    "        s_p = shortest_path(G,users[i],users[i+1])\n",
    "        if s_p[0] == 'Not possible':\n",
    "            return 'Not possible'\n",
    "        dist += s_p[0]\n",
    "        path.extend(s_p[1][1:])\n",
    "        \n",
    "    s_p = shortest_path(G,users[-1],target)\n",
    "    if s_p[0] == 'Not possible':\n",
    "            return 'Not possible'\n",
    "        \n",
    "    dist += s_p[0]\n",
    "    path.extend(s_p[1][1:]) \n",
    "    \n",
    "   \n",
    "    return dist,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c9a638a-e868-4275-a534-483d4cb594af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not possible'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functionality_3(G,[2,5],1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bee98-91be-4c4b-b233-c338e8513666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
